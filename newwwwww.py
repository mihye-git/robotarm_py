# -*- coding: utf-8 -*-
"""
MyCobot 320 M5 (pymycobot)
[ê°œì„  ë²„ì „ v5.10 - ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜]

ğŸ“Œ v5.9 ëŒ€ë¹„ í•µì‹¬ ë³€ê²½ì 
----------------------------------------------------
1. (ë¡œì§) YOLOê°€ í´ë˜ìŠ¤ ID(ìƒ‰ìƒ)ë¥¼ ê°ì§€í•˜ì—¬ ë¡œë´‡ ìŠ¤ë ˆë“œë¡œ ì „ë‹¬
   - [ìˆ˜ì •] g_target_object: (x, y, z) ì¢Œí‘œë¿ë§Œ ì•„ë‹ˆë¼ "class_id"ë„ í•¨ê»˜ ì €ì¥

2. (ë¡œì§) ë¡œë´‡ ìŠ¤ë ˆë“œê°€ class_idì— ë”°ë¼ 'ë‹¤ë¥¸' ìœ„ì¹˜ì— ë¬¼ì²´ë¥¼ ë‚´ë ¤ë†“ìŒ
   - (1=Blue -> Box1), (2=Red -> Box2), (3=Yellow -> Box3)

3. (ì¢Œí‘œ) ì‚¬ìš©ì ìš”ì²­ POSES ë”•ì…”ë„ˆë¦¬ ì „ì²´ ë°˜ì˜
   - ê¸°ì¡´ Clear_Air_A, Place_B ëŒ€ì‹  Box1_up, Box1 ë“±ìœ¼ë¡œ ëŒ€ì²´
"""

import threading
import cv2
import time
import argparse
import numpy as np
from ultralytics import YOLO
import queue  # [!!! v5.9 ì¶”ê°€ !!!]

# ---------------------------------------------------------------------------
# 0. ë¡œë´‡ í´ë˜ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°
# ---------------------------------------------------------------------------
try:
    from pymycobot.mycobot320 import MyCobot320 as CobotClass
except Exception:
    from pymycobot.mycobot import MyCobot as CobotClass

# ---------------------------------------------------------------------------
# 1. ì „ì—­ ë³€ìˆ˜, Lock, Event [!!! v5.10 ìˆ˜ì • !!!]
# ---------------------------------------------------------------------------
g_target_object = None          # [v5.10] YOLOê°€ ê³„ì‚°í•œ ë¡œë´‡ ì¢Œí‘œ + í´ë˜ìŠ¤ ID
g_coord_lock = threading.Lock() # ìœ„ ì¢Œí‘œë¥¼ ì•ˆì „í•˜ê²Œ ì½ê³  ì“°ê¸° ìœ„í•œ Lock
args = None                     # argparse ê²°ê³¼

# [v5.9] ìŠ¤ë ˆë“œ ê°„ í†µì‹ ìš© Event
e_robot_task_ready = threading.Event()  # YOLO -> Robot "ë¬¼ê±´ ì°¾ì•˜ë‹¤, ì¶œë°œí•´"
e_robot_task_done = threading.Event()   # Robot -> YOLO "ì‘ì—… ëë‚¬ë‹¤, ë‹¤ì‹œ ì°¾ì•„ë„ ë¼"
e_robot_task_done.set() # ì´ˆê¸° ìƒíƒœëŠ” "ì‘ì—… ì™„ë£Œ" (ì¦‰ì‹œ íƒì§€ ì‹œì‘ ê°€ëŠ¥)

# [v5.9] ìŠ¤ë ˆë“œ ê°„ í”„ë ˆì„ ì „ë‹¬ìš© Queue
frame_queue = queue.Queue(maxsize=1) 
# ë””ë²„ê·¸ ë° GUI í‘œì‹œìš© (YOLOê°€ ì²˜ë¦¬í•œ ìµœì¢… í”„ë ˆì„)
processed_frame_buffer = {"frame": None}

# ---------------------------------------------------------------------------
# 2. ë¡œë´‡ ê¸°ë³¸ ìì„¸/ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê°’ [!!! v5.10 ìˆ˜ì • !!!]
# ---------------------------------------------------------------------------
# [v5.10] ì‚¬ìš©ìê°€ ìš”ì²­í•œ POSES ë”•ì…”ë„ˆë¦¬ë¡œ ì „ì²´ êµì²´
POSES = {
    "Home":  [59.8, -215.9, 354.6, -175.33, 8.65, 86.68],  # ì‹œì‘/ëŒ€ê¸° ìœ„ì¹˜
    "Place": [105.8, -65.0, 483.4, -116.46, 4.87, -78.69],  # (ì‚¬ìš©ì ì •ì˜ - í˜„ì¬ ë¡œì§ì—ì„  ë¯¸ì‚¬ìš©)
    "Box1": [291.3, 210.0, 200, -172.57, -1.46, -87.15],  # 1. íŒŒë€ìƒ‰ ë†“ëŠ” ê³³
    "Box2": [333.4, 11.7, 200, -175.19, -0.08, -89.53],  # 2. ë¹¨ê°„ìƒ‰ ë†“ëŠ” ê³³
    "Box3": [319.9, -169.5, 200, -172.32, -2.86, -87.15],  # 3. ë…¸ë€ìƒ‰ ë†“ëŠ” ê³³
    "Box1_up": [229.8, 132.6, 386.4, -147.34, 9.15, -74.66],  # Box1 ì ‘ê·¼(ìœ„)
    "Box2_up": [264.0, -1.3, 379.0, -153.71, 11.7, -106.33], # Box2 ì ‘ê·¼(ìœ„)
    "Box3_up": [228.0, -203.0, 362.8, -146.13, 15.2, -149.53], # Box3 ì ‘ê·¼(ìœ„)
}

DEFAULT_SPEED = 20
CAMERA_MATRIX = np.array([
    [539.13729067, 0.0, 329.02126026],
    [0.0, 542.34217387, 242.10995541],
    [0.0, 0.0, 1.0]
])
DIST_COEFFS = np.array([[0.20528603, -0.76664068, -0.00096614, 0.00111892, 0.97630004]])

# ---------------------------------------------------------------------------
# 3. í”½ì…€ ì¢Œí‘œ â†’ ë¡œë´‡ ì¢Œí‘œ ë³€í™˜ (v5.9 ì›ë³¸)
# ---------------------------------------------------------------------------
def pixel_to_robot(cx, cy, distance_cm, frame_w, frame_h):
    # (v5.9ì™€ ë™ì¼)
    pts = np.array([[[cx, cy]]], dtype=np.float32)
    undistorted_pts = cv2.undistortPoints(pts, CAMERA_MATRIX, DIST_COEFFS, P=None)
    norm_x, norm_y = undistorted_pts[0, 0]
    scale_z = distance_cm * 10.0
    x_cam = norm_x * scale_z
    y_cam = norm_y * scale_z
    
    TCP_BASE_OFFSET_X = 59.8
    TCP_BASE_OFFSET_Y = -215.9
    CAMERA_TO_TCP_OFFSET_X = 90.0 
    CAMERA_TO_TCP_OFFSET_Y = 0.0
    
    robot_x = TCP_BASE_OFFSET_X + CAMERA_TO_TCP_OFFSET_X + y_cam
    robot_y = TCP_BASE_OFFSET_Y + CAMERA_TO_TCP_OFFSET_Y + x_cam
    
    TCP_BASE_OFFSET_Z = 354.6
    robot_z_ignored = TCP_BASE_OFFSET_Z - scale_z
    
    return {"x": round(robot_x, 2), "y": round(robot_y, 2), "z_debug": round(robot_z_ignored, 2)}

# ---------------------------------------------------------------------------
# 4. [ì‹ ê·œ v5.9] ì¹´ë©”ë¼ 'ì½ê¸°' ìŠ¤ë ˆë“œ (ì´ˆê³ ì† ì˜ìƒ ìˆ˜ê¸‰)
# ---------------------------------------------------------------------------
def camera_read_thread(stop_event, cap, frame_queue):
    # (v5.9ì™€ ë™ì¼)
    print("ğŸ“· ì¹´ë©”ë¼ 'ì½ê¸°' ìŠ¤ë ˆë“œ ì‹œì‘")
    while not stop_event.is_set():
        ret, frame = cap.read()
        if not ret:
            time.sleep(0.01)
            continue
        
        try:
            frame_queue.put_nowait(frame) 
        except queue.Full:
            pass
        
        time.sleep(0.01) 
    print("ğŸ“· ì¹´ë©”ë¼ 'ì½ê¸°' ìŠ¤ë ˆë“œ ì¢…ë£Œ")

# ---------------------------------------------------------------------------
# 5. [ìˆ˜ì • v5.10] 'YOLO ì²˜ë¦¬' ìŠ¤ë ˆë“œ (ëŠë¦° ë‘ë‡Œ)
# ---------------------------------------------------------------------------
def yolo_process_thread(stop_event, frame_queue, model):
    """Queueì—ì„œ í”„ë ˆì„ì„ êº¼ë‚´ì„œ YOLO ì˜ˆì¸¡ë§Œ ìˆ˜í–‰ (ëŠë¦¬ê²Œ ë™ì‘)"""
    global g_target_object, g_coord_lock, processed_frame_buffer # [v5.10]
    
    print("ğŸ§  YOLO 'ì²˜ë¦¬' ìŠ¤ë ˆë“œ ì‹œì‘")
    stable_frames = 0
    
    while not stop_event.is_set():
        # 1. ë¡œë´‡ì´ ì‘ì—… ì¤‘(e_robot_task_doneì´ False)ì´ë©´, íƒì§€ ì•ˆ í•¨
        if not e_robot_task_done.is_set():
            stable_frames = 0
            time.sleep(0.1)
            continue
            
        # 2. ë¡œë´‡ì´ ì‰¬ê³  ìˆìœ¼ë©´, Queueì—ì„œ ìµœì‹  í”„ë ˆì„ êº¼ë‚´ê¸°
        try:
            frame = frame_queue.get(timeout=0.1) 
        except queue.Empty:
            continue

        # 3. YOLO ì˜ˆì¸¡ (ê°€ì¥ ëŠë¦° ë¶€ë¶„)
        results = model.predict(frame, imgsz=640, conf=0.6, verbose=False)
        
        # [v5.10] ì¢Œí‘œì™€ í´ë˜ìŠ¤ IDë¥¼ í•¨ê»˜ ì¶”ì¶œ
        boxes = results[0].boxes.xyxy.cpu().numpy()
        classes = results[0].boxes.cls.cpu().numpy() # [v5.10]
        
        # 4. GUI í‘œì‹œìš© í”„ë ˆì„ ì €ì¥
        processed_frame_buffer["frame"] = results[0].plot()

        # 5. ë¬¼ì²´ ê°ì§€ ë° ì¢Œí‘œ ê³„ì‚°
        if len(boxes) > 0:
            stable_frames += 1
            if stable_frames >= 3: # 3í”„ë ˆì„ ì—°ì† ê°ì§€ ì‹œ "í™•ì •"
                x1, y1, x2, y2 = boxes[0]
                class_id = int(classes[0]) # [v5.10]
                
                cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)
                distance_cm = 19.0 # ì„ì‹œ ê³ ì •ê±°ë¦¬

                print(f"ğŸ¯ YOLO ê°ì²´ ì¤‘ì‹¬: ({cx}, {cy}), í´ë˜ìŠ¤ ID: {class_id}") # [v5.10]
                h, w, _ = frame.shape
                coord = pixel_to_robot(cx, cy, distance_cm, w, h)

                with g_coord_lock:
                    # [v5.10] ì¢Œí‘œì™€ í´ë˜ìŠ¤ IDë¥¼ í•¨ê»˜ ì €ì¥
                    g_target_object = {"coord": coord, "class_id": class_id} 
                
                e_robot_task_ready.set()  # ë¡œë´‡ ìŠ¤ë ˆë“œì—ê²Œ "ì¶œë°œ ì‹ í˜¸"
                e_robot_task_done.clear() # "íƒì§€ ì„ë¬´ ì™„ë£Œ, ë¡œë´‡ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°"
                stable_frames = 0
        else:
            stable_frames = 0
            
    print("ğŸ§  YOLO 'ì²˜ë¦¬' ìŠ¤ë ˆë“œ ì¢…ë£Œ")

# ---------------------------------------------------------------------------
# 6. [ìˆ˜ì • v5.10] 'ë¡œë´‡ ì œì–´' ìŠ¤ë ˆë“œ (ëŠë¦° íŒ”ë‹¤ë¦¬)
# ---------------------------------------------------------------------------
def robot_control_thread(stop_event, mc, dry_run):
    """ë¡œë´‡ì˜ ëª¨ë“  ì›€ì§ì„(sleep í¬í•¨)ì„ ì „ë‹´"""
    global g_target_object, g_coord_lock # [v5.10]
    
    print("ğŸ¤– ë¡œë´‡ 'ì œì–´' ìŠ¤ë ˆë“œ ì‹œì‘")
    
    # 1. (ë”± í•œ ë²ˆ) í™ˆ ìœ„ì¹˜ë¡œ ì´ë™
    if not dry_run and mc is not None:
        print("ğŸ¤– ë¡œë´‡ì„ í™ˆ ìœ„ì¹˜ë¡œ ì´ë™í•©ë‹ˆë‹¤...")
        mc.send_coords(POSES["Home"], DEFAULT_SPEED)
        time.sleep(3)
        print("ğŸ  í™ˆ ìœ„ì¹˜ ë„ë‹¬. íƒì§€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    else:
        print("ğŸ  [dry-run] í™ˆ ìœ„ì¹˜ ë„ë‹¬. íƒì§€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        
    e_robot_task_done.set() # YOLOê°€ íƒì§€ë¥¼ ì‹œì‘í•˜ë„ë¡ í—ˆìš©

    # 2. ë©”ì¸ ë£¨í”„ (ì‹ í˜¸ ëŒ€ê¸°)
    while not stop_event.is_set():
        # e_robot_task_ready ì‹ í˜¸ê°€ ì˜¬ ë•Œê¹Œì§€ ë¬´í•œì • ëŒ€ê¸° (Blocking)
        if not e_robot_task_ready.wait(timeout=0.5):
            continue # 0.5ì´ˆë§ˆë‹¤ stop_event ì²´í¬

        # ì‹ í˜¸ê°€ ì˜¤ë©´, ì¢Œí‘œì™€ í´ë˜ìŠ¤ IDë¥¼ ê°€ì ¸ì™€ì„œ ì „ì²´ ì‹œí€€ìŠ¤ ì‹¤í–‰
        current_task = None # [v5.10]
        with g_coord_lock:
            if g_target_object is not None: # [v5.10]
                current_task = g_target_object.copy() # [v5.10]
                g_target_object = None # [v5.10]
        
        if current_task: # [v5.10]
            current_coord = current_task["coord"]
            class_id = current_task["class_id"]
            
            print(f"ğŸ¤– ì¸ì‹ ì„±ê³µ â†’ ë¡œë´‡ ì´ë™ ì‹œì‘: {current_coord}, í´ë˜ìŠ¤ ID: {class_id}")
            pick_x = current_coord["x"]
            pick_y = current_coord["y"]

            # [v5.10] í´ë˜ìŠ¤ IDì— ë”°ë¼ ëª©í‘œ ìœ„ì¹˜ ê²°ì •
            # (ê°€ì •: 0=Blue/Box1, 1=Red/Box2, 2=Yellow/Box3)
            if class_id == 0: # 1. Blue
                place_pose_name = "Box1"
                approach_pose_name = "Box1_up"
            elif class_id == 1: # 2. Red
                place_pose_name = "Box2"
                approach_pose_name = "Box2_up"
            elif class_id == 2: # 3. Yellow
                place_pose_name = "Box3"
                approach_pose_name = "Box3_up"
            else:
                print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” í´ë˜ìŠ¤ ID: {class_id}. ê¸°ë³¸ê°’ 'Box2'ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
                place_pose_name = "Box2"
                approach_pose_name = "Box2_up"
            
            # POSES ë”•ì…”ë„ˆë¦¬ì—ì„œ ì‹¤ì œ ì¢Œí‘œ ë°°ì—´ ê°€ì ¸ì˜¤ê¸°
            place_pose = POSES[place_pose_name]
            approach_pose = POSES[approach_pose_name]
            print(f"  â†³ ëª©í‘œ ì§€ì : {place_pose_name}")

            # (v5.8 ì›ë³¸ ë¡œì§)
            GRIPPER_OFFSET_Z = 18.0
            FIXED_PICK_Z = 278.0
            APPROACH_HEIGHT = 40.0
            PICK_RX, PICK_RY, PICK_RZ = -175.33, 8.65, 86.68
            
            z_approach = FIXED_PICK_Z + APPROACH_HEIGHT
            z_grasp = FIXED_PICK_Z - GRIPPER_OFFSET_Z
            print(f"  â†³ ì ‘ê·¼Z={z_approach:.1f}, ì¡ê¸°Z={z_grasp:.1f}")

            if not dry_run and mc is not None:
                # --- v5.8 í”½ì—… ì‹œí€€ìŠ¤ (v5.10ì´ ë¡œì§ ì‚¬ìš©) ---
                mc.set_gripper_state(0, 80)
                time.sleep(1)
                mc.send_coords([pick_x, pick_y, z_approach, PICK_RX, PICK_RY, PICK_RZ], 25, 1)
                time.sleep(5)
                mc.send_coords([pick_x, pick_y, z_grasp, PICK_RX, PICK_RY, PICK_RZ], 15, 1)
                time.sleep(1.5)
                mc.set_gripper_state(1, 80)
                time.sleep(1.5)
                
                mc.send_coords([pick_x, pick_y, z_grasp + 80, PICK_RX, PICK_RY, PICK_RZ], 25, 1)
                time.sleep(2)
                
                # --- [!!! v5.10 ìˆ˜ì •ëœ ë¶€ë¶„ !!!] ---
                # ê¸°ì¡´ : POSES["Clear_Air_A"] -> POSES["Place_B"]
                # ë³€ê²½ : class_idì— ë”°ë¼ ì„ íƒëœ approach_pose -> place_pose
                mc.send_coords(approach_pose, DEFAULT_SPEED, 1) # ì˜ˆ: Box1_up
                time.sleep(3)
                mc.send_coords(place_pose, DEFAULT_SPEED, 1) # ì˜ˆ: Box1
                time.sleep(3)
                # --- [ìˆ˜ì • ì™„ë£Œ] ---
                
                mc.set_gripper_state(0, 80)
                time.sleep(1.5)
                mc.send_coords(POSES["Home"], DEFAULT_SPEED)
                time.sleep(3)
                print("âœ… 1íšŒ í”¼í‚¹ ì™„ë£Œ")
            else:
                print("  [dry-run] ë¡œë´‡ ì—†ì´ ë™ì‘ íë¦„ë§Œ ì‹¤í–‰")
                time.sleep(5) # ì‹œë®¬ë ˆì´ì…˜ ëŒ€ê¸°

            # ì‘ì—…ì´ ëë‚¬ìŒì„ ì•Œë¦¼
            e_robot_task_ready.clear() # "ì¶œë°œ ì‹ í˜¸" ë„ê¸°
            e_robot_task_done.set()  # YOLOì—ê²Œ "ë‹¤ì‹œ íƒì§€ ì‹œì‘" ì‹ í˜¸
            
    print("ğŸ¤– ë¡œë´‡ 'ì œì–´' ìŠ¤ë ˆë“œ ì¢…ë£Œ")

# ---------------------------------------------------------------------------
# 7. ë©”ì¸ ë£¨í”„ (GUI ë‹´ë‹¹)
# ---------------------------------------------------------------------------
def main():
    # (v5.9ì™€ ë™ì¼)
    global args

    parser = argparse.ArgumentParser()
    parser.add_argument("--port", type=str, default="/dev/ttyACM0")
    parser.add_argument("--baud", type=int, default=115200)
    parser.add_argument("--speed", type=int, default=20)
    parser.add_argument("--camera", type=int, default=1)
    parser.add_argument("--dry-run", action="store_true")
    parser.add_argument("--model", type=str, default="best.pt")
    args = parser.parse_args()

    print(f"ğŸ§  YOLOv8 ëª¨ë¸('{args.model}') ë¡œë“œ ì¤‘...")
    try:
        model = YOLO(args.model, task="detect")
        print("âœ… YOLO ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
    except Exception as e:
        print(f"âŒ YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
        
    stop_event = threading.Event()
    mc = None
    cap = None
    
    threads = [] 

    try:
        # 1) ë¡œë´‡ ì´ˆê¸°í™” (v5.9 ì›ë³¸)
        if not args.dry_run:
            try:
                mc = CobotClass(args.port, args.baud)
                time.sleep(0.5)
                mc.power_on()
                print("ğŸ”Œ ë¡œë´‡ Power ON ì™„ë£Œ")
                mc.set_gripper_state(0, 80)
                time.sleep(1)
            except Exception as e:
                print(f"âŒ ë¡œë´‡ ì—°ê²° ì‹¤íŒ¨: {e}")
                mc = None
                args.dry_run = True
        else:
            print("ğŸŸ¡ dry-run ëª¨ë“œë¡œ ì‹œì‘")

        # 2) ì¹´ë©”ë¼ ì´ˆê¸°í™” (v5.9 ì›ë³¸)
        print(f"ğŸ“· ë©”ì¸: ì¹´ë©”ë¼ {args.camera}ë²ˆ ì—´ê¸° ì‹œë„...")
        cap = cv2.VideoCapture(args.camera)
        if not cap.isOpened():
            print(f"âš ï¸ {args.camera}ë²ˆ ì¹´ë©”ë¼ ì‹¤íŒ¨ â†’ 0ë²ˆìœ¼ë¡œ ì¬ì‹œë„")
            cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            raise Exception("camera open failed")
        print("âœ… ë©”ì¸: ì¹´ë©”ë¼ ì—°ê²° ì„±ê³µ")

        # 3) [v5.9] 3ê°œì˜ ìŠ¤ë ˆë“œ ì‹œì‘
        
        # Thread 1: ì¹´ë©”ë¼ ì½ê¸°
        t_cam = threading.Thread(
            target=camera_read_thread, 
            args=(stop_event, cap, frame_queue), 
            daemon=True
        )
        t_cam.start()
        threads.append(t_cam)

        # Thread 2: YOLO ì²˜ë¦¬
        t_yolo = threading.Thread(
            target=yolo_process_thread, 
            args=(stop_event, frame_queue, model), 
            daemon=True
        )
        t_yolo.start()
        threads.append(t_yolo)

        # Thread 3: ë¡œë´‡ ì œì–´
        t_robot = threading.Thread(
            target=robot_control_thread, 
            args=(stop_event, mc, args.dry_run), 
            daemon=True
        )
        t_robot.start()
        threads.append(t_robot)

        print("âœ… ë©”ì¸ ë£¨í”„ ì‹œì‘ (GUI í‘œì‹œ ë‹´ë‹¹, që¡œ ì¢…ë£Œ)")
        
        # 4) ë©”ì¸ ë£¨í”„ (GUIë§Œ ë‹´ë‹¹)
        while not stop_event.is_set():
            frame = processed_frame_buffer.get("frame")
            
            if frame is None:
                try:
                    frame = frame_queue.get_nowait()
                except queue.Empty:
                    time.sleep(0.01)
                    continue

            cv2.imshow("Camera View", frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                stop_event.set()
                break
                
            time.sleep(0.01)

    except Exception as e:
        print(f"ğŸš¨ ë©”ì¸ ë£¨í”„ì—ì„œ ì—ëŸ¬ ë°œìƒ: {e}")
    finally:
        # 7) ì¢…ë£Œ ì²˜ë¦¬
        print("ğŸ›‘ ì¢…ë£Œ ì‹ í˜¸ ê°ì§€... ëª¨ë“  ìŠ¤ë ˆë“œ ì •ë¦¬ ì¤‘...")
        stop_event.set()
        
        for t in threads:
            t.join(timeout=1.0) 
            
        if cap:
            cap.release()
        cv2.destroyAllWindows()
        if mc:
            mc.power_off()
        print("ğŸ”’ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")


if __name__ == "__main__":
    main()