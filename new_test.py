# -*- coding: utf-8 -*-
"""
MyCobot 320 M5 (pymycobot)
[YOLO + ì¹´ë©”ë¼ë³´ì • ê¸°ë°˜ ì¢Œí‘œë³€í™˜ + ìŠ¤ë ˆë“œ ë¶„ë¦¬ + ê°ì§€ í›„ ì¹´ë©”ë¼ ìë™ì¢…ë£Œ + ì¢Œí‘œì €ì¥ v8.0]

ğŸ“Œ ì „ì²´ ìˆœì„œ
-------------------------------------------------
1ï¸âƒ£ ì¹´ë©”ë¼ ìŠ¤ë ˆë“œ: í”„ë ˆì„ ì†¡ì¶œë§Œ ìˆ˜í–‰
2ï¸âƒ£ ë©”ì¸ ë£¨í”„: ROI ë‚´ YOLO ê°ì§€ â†’ 3ì´ˆ ìœ ì§€ ì‹œ
3ï¸âƒ£ ì¢Œí‘œ ê³„ì‚°(pixel_to_robot) + JSON ì €ì¥
4ï¸âƒ£ ì¹´ë©”ë¼ ì¢…ë£Œ â†’ ë¡œë´‡ ì´ë™ (Homeâ†’Pickâ†’Placeâ†’Home)
"""

import threading
import cv2
import time
import argparse
import numpy as np
import json
import os
from ultralytics import YOLO

# ======================================================
# 0ï¸âƒ£ ë¡œë´‡ í´ë˜ìŠ¤ ë¡œë“œ
# ======================================================
try:
    from pymycobot.mycobot320 import MyCobot320 as CobotClass
except Exception:
    from pymycobot.mycobot import MyCobot as CobotClass


# ======================================================
# 1ï¸âƒ£ í¬ì¦ˆ ì •ì˜
# ======================================================
POSES = {
    "Home":  [59.8, -215.9, 354.6, -175.33, 8.65, 86.68],
    "Clear": [264.0, -1.0, 379.0, -153, 11, -106],
    "Place": [333.0, 11.0, 170.0, -175, -0.08, -89.0],
}
DEFAULT_SPEED = 20


# ======================================================
# 2ï¸âƒ£ ì¹´ë©”ë¼ ë³´ì •ê°’ ë¡œë“œ
# ======================================================
def load_camera_params(yaml_path="/home/vboxuser/robotarm/camera_info.yaml"):
    fs = cv2.FileStorage(yaml_path, cv2.FILE_STORAGE_READ)
    if not fs.isOpened():
        raise FileNotFoundError(f"âŒ '{yaml_path}' íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    camera_matrix = fs.getNode("camera_matrix").mat()
    dist_coeffs = fs.getNode("distortion_coefficients").mat()
    fs.release()
    print("ğŸ“· ì¹´ë©”ë¼ ë³´ì • íŒŒë¼ë¯¸í„° ë¡œë“œ ì™„ë£Œ")
    return camera_matrix, dist_coeffs


# ======================================================
# 3ï¸âƒ£ í”½ì…€ â†’ ë¡œë´‡ ì¢Œí‘œ ë³€í™˜ (ì˜¤í”„ì…‹ í¬í•¨)
# ======================================================
def pixel_to_robot(cx, cy, distance_cm, camera_matrix, dist_coeffs):
    pts = np.array([[[cx, cy]]], dtype=np.float32)
    undistorted = cv2.undistortPoints(pts, camera_matrix, dist_coeffs, P=None)
    norm_x, norm_y = undistorted[0, 0]

    # ê¹Šì´ ê³„ì‚° (cm â†’ mm)
    scale_z = distance_cm * 10.0
    x_cam = norm_x * scale_z
    y_cam = norm_y * scale_z

    # ----------------------------------------
    # ğŸ“ ì˜¤í”„ì…‹ (í…ŒìŠ¤íŠ¸ ê¸°ì¤€)
    # ----------------------------------------
    TCP_BASE_OFFSET_X = 59.8
    TCP_BASE_OFFSET_Y = -215.9
    TCP_BASE_OFFSET_Z = 354.6
    CAMERA_TO_TCP_OFFSET_X = 90.0   # â† ì¹´ë©”ë¼ê°€ Xë°©í–¥ìœ¼ë¡œ 90mm ì•ì— ìˆìŒ
    CAMERA_TO_TCP_OFFSET_Y = 0.0
    CAMERA_TO_TCP_OFFSET_Z = 170.0  # â† ì‹¤ì œ ë†’ì´ ì°¨ì´ (í˜„ì¬ëŠ” ì‚¬ìš© ì•ˆ í•¨)

    # ----------------------------------------
    # ë¡œë´‡ ì¢Œí‘œ ê³„ì‚°
    # ----------------------------------------
    robot_x = TCP_BASE_OFFSET_X + CAMERA_TO_TCP_OFFSET_X + y_cam
    robot_y = TCP_BASE_OFFSET_Y + CAMERA_TO_TCP_OFFSET_Y + x_cam

    # ZëŠ” í˜„ì¬ í…ŒìŠ¤íŠ¸ì—ì„œëŠ” ê³ ì • (ì›€ì§ì´ì§€ ì•ŠìŒ)
    robot_z = TCP_BASE_OFFSET_Z   # scale_z ì ìš© ì•ˆ í•¨

    return {"x": round(robot_x, 2), "y": round(robot_y, 2), "z": round(robot_z, 2)}



# ======================================================
# 4ï¸âƒ£ YOLO ê°ì§€ í•¨ìˆ˜
# ======================================================
def detect_yolo(model, frame):
    results = model.predict(frame, imgsz=640, conf=0.6, verbose=False)
    boxes = results[0].boxes.xyxy.cpu().numpy()
    frame_vis = results[0].plot()
    detected_info = []
    FIXED_DISTANCE_CM = 30.0

    if len(boxes) > 0:
        x1, y1, x2, y2 = boxes[0]
        cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)
        detected_info.append(("object", (cx, cy), FIXED_DISTANCE_CM))
    return frame_vis, detected_info


# ======================================================
# 5ï¸âƒ£ ì¹´ë©”ë¼ ìŠ¤ë ˆë“œ (í”„ë ˆì„ ì†¡ì¶œë§Œ)
# ======================================================
def camera_capture_thread(stop_event, frame_container):
    cap = cv2.VideoCapture(1)
    if not cap.isOpened():
        print("âš ï¸ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("ğŸ“· ì¹´ë©”ë¼ ìŠ¤ë ˆë“œ ì‹œì‘ (í”„ë ˆì„ ì†¡ì¶œ ì¤‘...)")
    while not stop_event.is_set():
        ret, frame = cap.read()
        if not ret:
            time.sleep(0.01)
            continue
        frame_container["frame"] = frame
    cap.release()
    print("ğŸ“· ì¹´ë©”ë¼ ìŠ¤ë ˆë“œ ì¢…ë£Œ")


# ======================================================
# 6ï¸âƒ£ ë¡œë´‡ ì´ë™ í—¬í¼
# ======================================================
def move_to(mc, name, speed=DEFAULT_SPEED):
    if name not in POSES:
        print(f"âš ï¸ Unknown pose: {name}")
        return
    target = POSES[name]
    mc.send_coords(target, speed, 1)
    time.sleep(2)
    print(f"âœ… Move â†’ {name}")


# ======================================================
# 7ï¸âƒ£ ì¢Œí‘œ JSON ì €ì¥
# ======================================================
def save_pick_coordinate(coord, filename="picking_target.json"):
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(coord, f, indent=4, ensure_ascii=False)
    print(f"ğŸ’¾ ì¢Œí‘œ ì €ì¥ ì™„ë£Œ â†’ {filename} : {coord}")


# ======================================================
# 8ï¸âƒ£ ë©”ì¸ ë£¨í”„
# ======================================================
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--port", type=str, default="/dev/ttyACM1")
    parser.add_argument("--baud", type=int, default=115200)
    parser.add_argument("--speed", type=int, default=20)
    parser.add_argument("--model", type=str, default="/home/vboxuser/robotarm/best.pt")
    parser.add_argument("--dry-run", action="store_true")
    args = parser.parse_args()

    # YOLO ëª¨ë¸ ë¡œë“œ
    print(f"ğŸ§  YOLO ëª¨ë¸ ë¡œë“œ ì¤‘: {args.model}")
    model = YOLO(args.model)
    print("âœ… YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    # ì¹´ë©”ë¼ ë³´ì •ê°’ ë¡œë“œ
    camera_matrix, dist_coeffs = load_camera_params()

    # ë¡œë´‡ ì—°ê²°
    mc = None
    if not args.dry_run:
        mc = CobotClass(args.port, args.baud)
        time.sleep(0.5)
        mc.power_on()
        print("ğŸ”Œ Power ON ì™„ë£Œ")
        move_to(mc, "Home", args.speed)
        mc.set_gripper_mode(0)
        mc.set_electric_gripper(0)
        mc.set_gripper_value(0, 20, 1)  # ì—´ë¦¼
    else:
        print("ğŸŸ¡ dry-run ëª¨ë“œ (ë¡œë´‡ ë¯¸ì—°ê²°)")

    # ì¹´ë©”ë¼ ìŠ¤ë ˆë“œ ì‹œì‘
    frame_container = {"frame": None}
    stop_event = threading.Event()
    cam_thread = threading.Thread(
        target=camera_capture_thread, args=(stop_event, frame_container), daemon=True
    )
    cam_thread.start()

    print("âœ… ë©”ì¸ ë£¨í”„ ì‹œì‘ (ROI ê°ì§€ í›„ 3ì´ˆ ìœ ì§€ ì‹œ ì‹¤í–‰)")
    roi_detect_start = None
    DETECT_HOLD_TIME = 3.0
    detected_coord = None

    try:
        while not stop_event.is_set():
            frame = frame_container.get("frame")
            if frame is None:
                continue

            # ROI í‘œì‹œ
            h, w, _ = frame.shape
            roi_x1, roi_y1 = int(w * 0.3), int(h * 0.3)
            roi_x2, roi_y2 = int(w * 0.7), int(h * 0.7)
            cv2.rectangle(frame, (roi_x1, roi_y1), (roi_x2, roi_y2), (0, 255, 0), 2)
            cv2.drawMarker(frame, (w // 2, h // 2), (0, 255, 0), cv2.MARKER_CROSS, 15, 2)

            processed_frame, detected = detect_yolo(model, frame)
            in_roi = False

            if detected:
                _, (cx, cy), dist = detected[0]
                if roi_x1 < cx < roi_x2 and roi_y1 < cy < roi_y2:
                    in_roi = True

            if in_roi:
                if roi_detect_start is None:
                    roi_detect_start = time.time()
                    print("ğŸ”µ ROI ê°ì§€ ì‹œì‘ (3ì´ˆ ìœ ì§€ ì‹œ ì¢Œí‘œ í™•ì •)")
                else:
                    elapsed = time.time() - roi_detect_start
                    cv2.putText(processed_frame, f"ê°ì§€ ì¤‘... {elapsed:.1f}s", (20, 40),
                                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)
                    if elapsed >= DETECT_HOLD_TIME:
                        print("ğŸŸ¢ ê°ì§€ ìœ ì§€ 3ì´ˆ â†’ ì¢Œí‘œ ê³„ì‚° ì‹œì‘")
                        detected_coord = pixel_to_robot(cx, cy, dist, camera_matrix, dist_coeffs)
                        print(f"ğŸ¯ ë¬¼ì²´ ì¢Œí‘œ: {detected_coord}")
                        # ê°ì§€ëœ ë¬¼ì²´ ì¢Œí‘œ
                        # save_pick_coordinate(detected_coord)

                        # âœ… ì¹´ë©”ë¼ ì¢…ë£Œ
                        stop_event.set()
                        cam_thread.join()
                        cv2.destroyAllWindows()
                        print("ğŸ“· ì¹´ë©”ë¼ ì¢…ë£Œ ì™„ë£Œ")

                        break
            else:
                roi_detect_start = None

            cv2.imshow("Camera View", processed_frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                stop_event.set()
                break

    finally:
        stop_event.set()
        cam_thread.join()
        cv2.destroyAllWindows()

    # ==================================================
    # âœ… ê°ì§€ëœ ì¢Œí‘œê°€ ìˆìœ¼ë©´ ë¡œë´‡ ì´ë™
    # ==================================================
    if detected_coord:
        print("ğŸ¤– ë¡œë´‡ ì´ë™ ì‹œì‘...")
        if not args.dry_run and mc:
            mc.set_gripper_state(0, 80)   # ì™„ì „ ì—´ê¸°
            mc.send_coords([detected_coord["x"], detected_coord["y"], 300.0, -175.33, 8.65, 86.68], 25, 1)
            time.sleep(3)
            mc.send_coords([detected_coord["x"]-15, detected_coord["y"], 260.0+30, -175.33, 8.65, 86.68], 15, 1)
            time.sleep(2)
            mc.set_gripper_state(1, 80)   # ë‹«ê¸°
            mc.send_coords([detected_coord["x"], detected_coord["y"], 260.0+50, -175.33, 8.65, 86.68], 15, 1)
            time.sleep(2)
            #ë©ˆì¶¤
            # exit()
            time.sleep(1.5)
            move_to(mc, "Clear", args.speed)
            move_to(mc, "Place", args.speed)
            mc.set_gripper_state(0, 80)
            move_to(mc, "Home", args.speed)
        else:
            print(f"ğŸŸ¢ [dry-run] ì¢Œí‘œ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ: {detected_coord}")

    if mc:
        mc.power_off()
    print("ğŸ”’ ì¢…ë£Œ ì™„ë£Œ")


if __name__ == "__main__":
    main()
